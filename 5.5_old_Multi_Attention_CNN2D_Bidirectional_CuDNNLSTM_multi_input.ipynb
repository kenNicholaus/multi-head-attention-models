{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIf you are running locally then \\n1. reboot your local machine\\n2. create an environment called 'colab' using anaconda prompt\\nif you have a gpu\\nconda create -n colab python tensorflow-gpu \\nif not \\nconda create -n colab python tensorflow\\n3. to install jupyter notebook\\nconda install jupyter notebook\\n4. to go to the 'colab' environment\\nactivate colab\\n5. change file path to locate this notebook and then type 'jupyter notebook'\\n\\nIf you use colab\\n1. save the data file in your google drive\\n2. goto colab and start running the code\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "If you are running locally then \n",
    "1. reboot your local machine\n",
    "2. create an environment called 'colab' using anaconda prompt\n",
    "if you have a gpu\n",
    "conda create -n colab python tensorflow-gpu \n",
    "if not \n",
    "conda create -n colab python tensorflow\n",
    "3. to install jupyter notebook\n",
    "conda install jupyter notebook\n",
    "4. to go to the 'colab' environment\n",
    "activate colab\n",
    "5. change file path to locate this notebook and then type 'jupyter notebook'\n",
    "\n",
    "If you use colab\n",
    "1. save the data file in your google drive\n",
    "2. goto colab and start running the code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install prominent libraries with specific versions\n",
    "\n",
    "#!pip install tensorflow==1.15.0\n",
    "#!pip install keras==2.2.4-tf\n",
    "#!pip install pandas==0.25.1\n",
    "#!pip install sklearn==0.21.3\n",
    "#!pip install matplotlib==3.2.1\n",
    "#!pip install hyperas\n",
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "sJnnN6xG_yaM",
    "outputId": "b6420ce8-7f05-440c-e2ce-479b5bc1cafc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, CuDNNLSTM, GRU, Input, Activation, Flatten, BatchNormalization, Reshape,Bidirectional\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard, History, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.python.keras import regularizers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from tensorflow.python.keras.optimizers import SGD, RMSprop, Adam, Adadelta\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from sklearn.preprocessing import *\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.layers import Dense, Input, LSTM, Bidirectional, Activation, Conv1D, GRU, TimeDistributed\n",
    "from tensorflow.python.keras.layers import Dropout, Embedding, GlobalMaxPooling1D, MaxPooling1D, Add, Flatten, SpatialDropout1D\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling1D, BatchNormalization, concatenate\n",
    "from tensorflow.python.keras.layers import Reshape, merge, Concatenate, Lambda, Average\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import initializers, regularizers, constraints\n",
    "from tensorflow.python.keras.initializers import *\n",
    "import hyperas\n",
    "import hyperopt\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe, rand\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow.__version__ =  1.10.0\n",
      "sklearn.__version__ =  0.21.3\n",
      "numpy.__version__ =  1.17.0\n",
      "pandas.__version__ =  1.0.1\n",
      "matplotlib.__version__ =  3.1.3\n"
     ]
    }
   ],
   "source": [
    "#Get library versions\n",
    "print(\"tensorflow.__version__ = \", tf.__version__)\n",
    "# import tensorflow.python.keras\n",
    "# print(\"keras.__version__ = \", tensorflow.python.keras.__version__)\n",
    "import sklearn \n",
    "print(\"sklearn.__version__ = \", sklearn.__version__)\n",
    "print(\"numpy.__version__ = \", np.__version__)\n",
    "print(\"pandas.__version__ = \", pd.__version__)\n",
    "import matplotlib\n",
    "print(\"matplotlib.__version__ = \", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed to generate reproduceable results\n",
    "from numpy.random import seed\n",
    "seed(56)\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(56)\n",
    "random.seed(56)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "os.environ['TF_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they do not exist\n",
    "def build_path(dirName):\n",
    "    try:\n",
    "        os.makedirs(dirName)    \n",
    "        print(\"Directory \" , dirName ,  \" Created \")\n",
    "    except:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13481044582615228507\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7139449242\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9396741898385275843\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# to check if GPU is getting used locally.....you need to see CPU as well as GPU in the output\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOs6JYN__51O"
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "  i = 7 # the label target - number of days to predict from the input date\n",
    "  p = 7 #Number of days for target calculated in the data set\n",
    "  batch_size=512\n",
    "  CLASSES = 2\n",
    "  time_steps = 7\n",
    "  ticker='^GSPC'\n",
    "    \n",
    "  # read data\n",
    "  df=pd.read_csv('../^GSPC_7_days_0_return_dtw.csv', index_col = 0, parse_dates = True)\n",
    "    \n",
    "  #add additional rolling mean data  \n",
    "  rm_window =30\n",
    "  rolling_mean = []\n",
    "  for a in range(2,rm_window+1):\n",
    "    df[ticker+'rm_'+str(a)] = df[ticker].rolling(window=rm_window,center=False).mean()\n",
    "    rolling_mean.append(ticker+'rm_'+str(a))\n",
    "    \n",
    "  # create label\n",
    "  targets=pd.DataFrame([])\n",
    "  for j in range (1, p+1):\n",
    "    targets=targets.append(df[ticker+'_{}d_target'.format(j)])\n",
    "    targets=targets.append(df[ticker+'_{}d'.format(j)])\n",
    "  targets=targets.T\n",
    "  df=df.drop(targets.columns, axis=1)\n",
    "  df=df[rm_window:-i]\n",
    "  targets=targets[rm_window:-i]\n",
    "  y=targets['^GSPC_{}d_target'.format(i)]\n",
    "\n",
    "  #check for NaN and remove\n",
    "  df.isna().mean().sum()\n",
    "  y.isna().mean().sum()\n",
    "  remove_list=[]\n",
    "  for i in df.isnull().any().iteritems():\n",
    "    if i[1] == True:\n",
    "      remove_list.append(i[0])\n",
    "  df=df.drop(remove_list, axis=1)\n",
    "  df.isnull().any().mean()\n",
    " \n",
    "  # add percent change\n",
    "  df=df.pct_change()\n",
    "  df=df.replace([np.inf, -np.inf],np.nan) \n",
    "  df.fillna(0, inplace=True)\n",
    "  df.isnull().any().mean()\n",
    "    \n",
    "  # apply preprocessing \n",
    "  x_scaler=RobustScaler()\n",
    "  x = x_scaler.fit_transform(df)\n",
    "  # x_pred = x_scaler.fit_transform(x_pred)\n",
    "  del df\n",
    "  y=y.values\n",
    "    \n",
    "  # apply time steps\n",
    "  def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "      v = X[i:(i + time_steps)]\n",
    "      Xs.append(v)\n",
    "      ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "  x, y = create_dataset(x, y, time_steps)\n",
    "\n",
    "  # create train and test dataset\n",
    "  x_train, x_test, y_train, y_test=train_test_split(x,y, train_size=0.7, random_state=54)\n",
    "  x_train = x_train.astype('float32')\n",
    "  x_test = x_test.astype('float32')\n",
    "  #y_train = y_train.astype('float32')\n",
    "  #y_test = y_test.astype('float32')\n",
    "  y_train = np_utils.to_categorical(y_train, CLASSES, \n",
    "                                    #dtype='float32'\n",
    "                                   )\n",
    "  y_test = np_utils.to_categorical(y_test, CLASSES, \n",
    "                                   #dtype='float32'\n",
    "                                  )\n",
    "    \n",
    "  # adjustment for batch_size\n",
    "  train_start = x_train.shape[0]%batch_size\n",
    "  test_start = x_test.shape[0]%batch_size\n",
    "  x_train = x_train[train_start:]\n",
    "  y_train = y_train[train_start:]\n",
    "  x_test = x_test[test_start:]\n",
    "  y_test = y_test[test_start:]\n",
    "\n",
    "  #reshape for 2D\n",
    "  x_train1 = x_train.reshape(x_train.shape[0], 1, x_train.shape[1], x_train.shape[2]) \n",
    "  x_test1 = x_test.reshape(x_test.shape[0], 1, x_test.shape[1], x_test.shape[2])  \n",
    "\n",
    "  embed_size = 60\n",
    "\n",
    "  return x_train, x_test, y_train, y_test, batch_size, time_steps, embed_size, x_train1, x_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rc8hDOIbADgQ"
   },
   "outputs": [],
   "source": [
    "def create_multi_attention_cnn2D_bidirectional_cudnnlstm_multi_input_model(x_train, x_test, y_train, y_test, batch_size, time_steps, embed_size, x_train1, x_test1):\n",
    "    \n",
    "    class LayerNormalization(Layer):\n",
    "        def __init__(self, eps=1e-6, **kwargs):\n",
    "            self.eps = eps\n",
    "            super(LayerNormalization, self).__init__(**kwargs)\n",
    "        def build(self, input_shape):\n",
    "            self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],initializer=Ones(), trainable=True)\n",
    "            self.beta = self.add_weight(name='beta', shape=input_shape[-1:],initializer=Zeros(), trainable=True)\n",
    "            super(LayerNormalization, self).build(input_shape)\n",
    "        def call(self, x):\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            std = K.std(x, axis=-1, keepdims=True)\n",
    "            return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return input_shape\n",
    "\n",
    "    class ScaledDotProductAttention():\n",
    "        def __init__(self, d_model, attn_dropout=0.1):\n",
    "            self.temper = np.sqrt(d_model)\n",
    "            self.dropout = Dropout(attn_dropout)\n",
    "        def __call__(self, q, k, v, mask):\n",
    "            attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k])\n",
    "            if mask is not None:\n",
    "                mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
    "                attn = Add()([attn, mmask])\n",
    "            attn = Activation('softmax')(attn)\n",
    "            attn = self.dropout(attn)\n",
    "            output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
    "            return output, attn\n",
    "\n",
    "    class MultiHeadAttention():\n",
    "        # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
    "        def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True):\n",
    "            self.mode = mode\n",
    "            self.n_head = n_head\n",
    "            self.d_k = d_k\n",
    "            self.d_v = d_v\n",
    "            self.dropout = dropout\n",
    "            if mode == 0:\n",
    "                self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
    "                self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
    "                self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
    "            elif mode == 1:\n",
    "                self.qs_layers = []\n",
    "                self.ks_layers = []\n",
    "                self.vs_layers = []\n",
    "                for _ in range(n_head):\n",
    "                    self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                    self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                    self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
    "            self.attention = ScaledDotProductAttention(d_model)\n",
    "            self.layer_norm = LayerNormalization() if use_norm else None\n",
    "            self.w_o = TimeDistributed(Dense(d_model))\n",
    "\n",
    "        def __call__(self, q, k, v, mask=None):\n",
    "            d_k, d_v = self.d_k, self.d_v\n",
    "            n_head = self.n_head\n",
    "\n",
    "            if self.mode == 0:\n",
    "                qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
    "                ks = self.ks_layer(k)\n",
    "                vs = self.vs_layer(v)\n",
    "\n",
    "                def reshape1(x):\n",
    "                    s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
    "                    x = tf.reshape(x, [s[0], s[1], n_head, d_k])\n",
    "                    x = tf.transpose(x, [2, 0, 1, 3])  \n",
    "                    x = tf.reshape(x, [-1, s[1], d_k])  # [n_head * batch_size, len_q, d_k]\n",
    "                    return x\n",
    "                qs = Lambda(reshape1)(qs)\n",
    "                ks = Lambda(reshape1)(ks)\n",
    "                vs = Lambda(reshape1)(vs)\n",
    "\n",
    "                if mask is not None:\n",
    "                    mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
    "                head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
    "\n",
    "                def reshape2(x):\n",
    "                    s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
    "                    x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
    "                    x = tf.transpose(x, [1, 2, 0, 3])\n",
    "                    x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
    "                    return x\n",
    "                head = Lambda(reshape2)(head)\n",
    "            elif self.mode == 1:\n",
    "                heads = []; attns = []\n",
    "                for i in range(n_head):\n",
    "                    qs = self.qs_layers[i](q)   \n",
    "                    ks = self.ks_layers[i](k) \n",
    "                    vs = self.vs_layers[i](v) \n",
    "                    head, attn = self.attention(qs, ks, vs, mask)\n",
    "                    heads.append(head); attns.append(attn)\n",
    "                head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
    "                attn = Concatenate()(attns) if n_head > 1 else attns[0]\n",
    "\n",
    "            outputs = self.w_o(head)\n",
    "            outputs = Dropout(self.dropout)(outputs)\n",
    "            if not self.layer_norm: return outputs, attn\n",
    "            # outputs = Add()([outputs, q]) # sl: fix\n",
    "            return self.layer_norm(outputs), attn\n",
    "\n",
    "    class PositionwiseFeedForward():\n",
    "        def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "            self.w_1 = Conv1D(d_inner_hid, 1, activation='relu')\n",
    "            self.w_2 = Conv1D(d_hid, 1)\n",
    "            self.layer_norm = LayerNormalization()\n",
    "            self.dropout = Dropout(dropout)\n",
    "        def __call__(self, x):\n",
    "            output = self.w_1(x) \n",
    "            output = self.w_2(output)\n",
    "            output = self.dropout(output)\n",
    "            output = Add()([output, x])\n",
    "            return self.layer_norm(output)\n",
    "\n",
    "    class EncoderLayer():\n",
    "        def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "            self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "            self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "        def __call__(self, enc_input, mask=None):\n",
    "            output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
    "            output = self.pos_ffn_layer(output)\n",
    "            return output, slf_attn\n",
    "\n",
    "\n",
    "    def GetPosEncodingMatrix(max_len, d_emb):\n",
    "        pos_enc = np.array([\n",
    "            [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
    "            if pos != 0 else np.zeros(d_emb) \n",
    "                for pos in range(max_len)\n",
    "                ])\n",
    "        pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "        pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "        return pos_enc\n",
    "\n",
    "    def GetPadMask(q, k):\n",
    "        ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "        mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "        mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "        return mask\n",
    "\n",
    "    def GetSubMask(s):\n",
    "        len_s = tf.shape(s)[1]\n",
    "        bs = tf.shape(s)[:1]\n",
    "        mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
    "        return mask\n",
    "\n",
    "    class Transformer():\n",
    "        def __init__(self, len_limit, embedding_matrix, d_model=embed_size, \\\n",
    "                  d_inner_hid=512, n_head=10, d_k=64, d_v=64, layers=2, dropout=0.1, \\\n",
    "                  share_word_emb=False, **kwargs):\n",
    "            self.name = 'Transformer'\n",
    "            self.len_limit = len_limit\n",
    "            self.src_loc_info = False # True # sl: fix later\n",
    "            self.d_model = d_model\n",
    "            self.decode_model = None\n",
    "            d_emb = d_model\n",
    "\n",
    "            pos_emb = Embedding(len_limit, d_emb, trainable=False, \\\n",
    "                                weights=[GetPosEncodingMatrix(len_limit, d_emb)])\n",
    "\n",
    "            i_word_emb = Embedding(max_features, d_emb, weights=[embedding_matrix]) # Add Kaggle provided embedding here\n",
    "\n",
    "            self.encoder = Encoder(d_model, d_inner_hid, n_head, d_k, d_v, layers, dropout, \\\n",
    "                                   word_emb=i_word_emb, pos_emb=pos_emb)\n",
    "\n",
    "\n",
    "        def get_pos_seq(self, x):\n",
    "            mask = K.cast(K.not_equal(x, 0), 'int32')\n",
    "            pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
    "            return pos * mask\n",
    "\n",
    "        \n",
    "    # define two sets of inputs(it can be the same or different)\n",
    "    inputA = Input(batch_shape=(batch_size, x_train1.shape[1], x_train1.shape[2], x_train1.shape[3]), name='input_1')\n",
    "    inputB = Input(batch_shape=(batch_size, x_train.shape[1], x_train.shape[2]), name='input_2')\n",
    "\n",
    "    # the first branch operates on the first input\n",
    "    x1 = Conv2D(filters = {{choice([32, 64, 128])}},name='x1', kernel_size =2,padding='same', activation='relu')(inputA)\n",
    "    x2 = MaxPooling2D(pool_size=(2,2), strides=(2,2), data_format=\"channels_first\", name='x2')(x1)\n",
    "    x3 = Conv2D(filters ={{choice([16, 32, 64])}}, name='x3', kernel_size =2,padding='same', activation='relu')(x2)\n",
    "    x4 = MaxPooling2D(pool_size=(2,2), strides=(2,2), data_format=\"channels_first\", name='x4')(x3)\n",
    "    x5 = Flatten(name='x5')(x4)\n",
    "    x6 = Dense(units = {{choice([4, 8,16,32])}},name='x6', activation='relu')(x5)\n",
    "    x = Model(inputA, x6, name='x')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    y1 = Bidirectional(CuDNNLSTM(units = {{choice([16,32, 64, 128])}}, name='x1',  kernel_regularizer=regularizers.l2(0.03), \n",
    "              bias_regularizer=regularizers.l1(0.03),\n",
    "              return_sequences=True, stateful = True))(inputB)\n",
    "    y2 = BatchNormalization(name='y2')(y1)\n",
    "    y3 = Dropout({{uniform(0, 1)}},name='y3')(y2)\n",
    "    \n",
    "    \n",
    "    if {{choice(['three', 'four','five'])}} == 'three':\n",
    "        y4, slf_attn = MultiHeadAttention(n_head=3, d_model={{choice([16, 32, 64, 128])}}, d_k=64, d_v=64, dropout={{uniform(0, 1)}})(y3, y3, y3)\n",
    "    elif 'four':\n",
    "        y4, slf_attn = MultiHeadAttention(n_head=4, d_model={{choice([16, 32, 64, 128])}}, d_k=64, d_v=64, dropout={{uniform(0, 1)}})(y3, y3, y3)\n",
    "    elif 'five':\n",
    "        y4, slf_attn = MultiHeadAttention(n_head=5, d_model={{choice([16, 32, 64, 128])}}, d_k=64, d_v=64, dropout={{uniform(0, 1)}})(y3, y3, y3)   \n",
    "    \n",
    "    y5 = Bidirectional(CuDNNLSTM(units = {{choice([16, 32, 64, 128])}},name='y5',  kernel_regularizer=regularizers.l2(0.03), \n",
    "              bias_regularizer=regularizers.l1(0.03),\n",
    "              return_sequences=False,stateful = True))(y4)\n",
    "    y6 = BatchNormalization(name='y6')(y5)\n",
    "    y7 = Dropout({{uniform(0, 1)}},name='y7')(y6)\n",
    "    \n",
    "    if {{choice(['dense', 'nodense'])}} == 'dense':\n",
    "    \n",
    "        y8 = Dense(units = {{choice([8, 16, 32, 64])}}, name='y8', kernel_regularizer=regularizers.l2(0.03), bias_regularizer=regularizers.l1(0.03),\n",
    "                   activation='relu')(y7)\n",
    "        y9 = Dropout({{uniform(0, 1)}}, name='x9')(y8)\n",
    "    \n",
    "        y10 = Dense(units = {{choice([4, 8, 16, 32])}}, activation='relu')(y9)\n",
    "    else:\n",
    "        y10 = Dense(units = {{choice([4, 8, 16, 32])}}, activation='relu')(y7)\n",
    "        \n",
    "    y = Model(inputB, y10, name='y')\n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = Concatenate(name='x_y_output_combined')([x.output, y.output])\n",
    "    z1 = Dropout(0.3)(combined)\n",
    "\n",
    "    # combined outputs\n",
    "    z = Dense(2, name='z', activation=\"softmax\")(z1)\n",
    "\n",
    "    # our model will accept the inputs of the two branches and then output buy or sell\n",
    "    model = Model(inputs=[inputA, inputB], outputs=z)\n",
    "    \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer = Adam(lr=0.001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    result = model.fit([x_train1, x_train],y_train,batch_size=batch_size,epochs=10,validation_data=([x_test1, x_test], y_test), verbose=0)\n",
    "    \n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "\n",
    "    print('Best validation acc of epoch:', result.history['val_acc'])\n",
    "    print('Train acc of epoch:', result.history['acc'])\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HcxtusN4AK8y",
    "outputId": "43d151c2-cf3b-4ab8-e95f-7c48cef1da49",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8704, 7, 2782) (8704, 2) (3584, 7, 2782) (3584, 2)\n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional (Bidirectional)   (512, 7, 128)        1458176     input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 128)        512         bidirectional[0][0]                                   \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 128)        0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense (Dense)                   (512, 7, 192)        24576       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_1 (Dense)                 (512, 7, 192)        24576       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda (Lambda)                 (1536, 7, 64)        0           dense[0][0]                                           \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_1 (Lambda)               (1536, 7, 64)        0           dense_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_3 (Lambda)               (1536, 7, 7)         0           lambda[0][0]                                          \n",
      "                                                                 lambda_1[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "activation (Activation)         (1536, 7, 7)         0           lambda_3[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_2 (Dense)                 (512, 7, 192)        24576       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout (Dropout)               (1536, 7, 7)         0           activation[0][0]                                      \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_2 (Lambda)               (1536, 7, 64)        0           dense_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_4 (Lambda)               (1536, 7, 64)        0           dropout[0][0]                                         \n",
      "                                                                 lambda_2[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_5 (Lambda)               (512, 7, 192)        0           lambda_4[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed (TimeDistribut (512, 7, 128)        24704       lambda_5[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_1 (Dropout)             (512, 7, 128)        0           time_distributed[0][0]                                \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization (LayerNorma (512, 7, 128)        256         dropout_1[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 64)      712256      input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_1 (Bidirectional) (512, 128)           99328       layer_normalization[0][0]                             \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 32)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 128)           512         bidirectional_1[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 64)      8256        x2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 128)           0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 32)      0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y8 (Dense)                      (512, 8)             1032        y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 32)            0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x9 (Dropout)                    (512, 8)             0           y8[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 32)            1056        x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_4 (Dense)                 (512, 4)             36          x9[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_y_output_combined (Concatenat (512, 36)            0           x6[0][0]                                              \n",
      "                                                                 dense_4[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_2 (Dropout)             (512, 36)            0           x_y_output_combined[0][0]                             \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             74          dropout_2[0][0]                                       \n",
      "==================================================================================================                     \n",
      "Total params: 2,379,926                                                                                                \n",
      "Trainable params: 2,379,414                                                                                            \n",
      "Non-trainable params: 512                                                                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5103236607142857, 0.521484375, 0.5438058035714286, 0.5454799107142857, 0.5516183035714286, 0.5521763392857143, 0.5530133928571429, 0.552734375, 0.5530133928571429, 0.5530133928571429]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5042509191176471, 0.5456112132352942, 0.5531939338235294, 0.5657169117647058, 0.5656020220588235, 0.5661764705882353, 0.5745634191176471, 0.5712316176470589, 0.5736443014705882, 0.5730698529411765]\n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_2 (Bidirectional) (512, 7, 64)         720896      input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 64)         256         bidirectional_2[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 64)         0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_5 (Dense)                 (512, 7, 256)        16384       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_6 (Dense)                 (512, 7, 256)        16384       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_6 (Lambda)               (2048, 7, 64)        0           dense_5[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_7 (Lambda)               (2048, 7, 64)        0           dense_6[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_9 (Lambda)               (2048, 7, 7)         0           lambda_6[0][0]                                        \n",
      "                                                                 lambda_7[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "activation_1 (Activation)       (2048, 7, 7)         0           lambda_9[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_7 (Dense)                 (512, 7, 256)        16384       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_3 (Dropout)             (2048, 7, 7)         0           activation_1[0][0]                                    \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_8 (Lambda)               (2048, 7, 64)        0           dense_7[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_10 (Lambda)              (2048, 7, 64)        0           dropout_3[0][0]                                       \n",
      "                                                                 lambda_8[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_11 (Lambda)              (512, 7, 256)        0           lambda_10[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed_1 (TimeDistrib (512, 7, 128)        32896       lambda_11[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_4 (Dropout)             (512, 7, 128)        0           time_distributed_1[0][0]                              \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization_1 (LayerNor (512, 7, 128)        256         dropout_4[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 128)     1424512     input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_3 (Bidirectional) (512, 32)            18688       layer_normalization_1[0][0]                           \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 64)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 32)            128         bidirectional_3[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 16)      4112        x2[0][0]                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 32)            0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 8)       0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y8 (Dense)                      (512, 16)            528         y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 8)             0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x9 (Dropout)                    (512, 16)            0           y8[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 8)             72          x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_9 (Dense)                 (512, 4)             68          x9[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 12)            0           x6[0][0]                                              \n",
      "                                                                 dense_9[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_5 (Dropout)             (512, 12)            0           x_y_output_combined[0][0]                             \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             26          dropout_5[0][0]                                       \n",
      "==================================================================================================                     \n",
      "Total params: 2,251,590                                                                                                \n",
      "Trainable params: 2,251,398                                                                                            \n",
      "Non-trainable params: 192                                                                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5362723214285714, 0.5485491071428571, 0.552734375, 0.5552455357142857, 0.552734375, 0.5560825892857143, 0.556640625, 0.5510602678571429, 0.5365513392857143, 0.5613839285714286]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5217141544117647, 0.5477941176470589, 0.5517003676470589, 0.5548023897058824, 0.5558363970588235, 0.5611213235294118, 0.5614659926470589, 0.5590533088235294, 0.5499770220588235, 0.5521599264705882]\n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_4 (Bidirectional) (512, 7, 64)         720896      input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 64)         256         bidirectional_4[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 64)         0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_10 (Dense)                (512, 7, 192)        12288       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_11 (Dense)                (512, 7, 192)        12288       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_12 (Lambda)              (1536, 7, 64)        0           dense_10[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_13 (Lambda)              (1536, 7, 64)        0           dense_11[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_15 (Lambda)              (1536, 7, 7)         0           lambda_12[0][0]                                       \n",
      "                                                                 lambda_13[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "activation_2 (Activation)       (1536, 7, 7)         0           lambda_15[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_12 (Dense)                (512, 7, 192)        12288       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_6 (Dropout)             (1536, 7, 7)         0           activation_2[0][0]                                    \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_14 (Lambda)              (1536, 7, 64)        0           dense_12[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_16 (Lambda)              (1536, 7, 64)        0           dropout_6[0][0]                                       \n",
      "                                                                 lambda_14[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_17 (Lambda)              (512, 7, 192)        0           lambda_16[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_distributed_2 (TimeDistrib (512, 7, 64)         12352       lambda_17[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 64)      712256      input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_7 (Dropout)             (512, 7, 64)         0           time_distributed_2[0][0]                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 32)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization_2 (LayerNor (512, 7, 64)         128         dropout_7[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 64)      8256        x2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_5 (Bidirectional) (512, 64)            25088       layer_normalization_2[0][0]                           \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 32)      0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 64)            256         bidirectional_5[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 32)            0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 64)            0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 16)            528         x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_14 (Dense)                (512, 16)            1040        y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 32)            0           x6[0][0]                                              \n",
      "                                                                 dense_14[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_8 (Dropout)             (512, 32)            0           x_y_output_combined[0][0]                             \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             66          dropout_8[0][0]                                       \n",
      "==================================================================================================                     \n",
      "Total params: 1,517,986                                                                                                \n",
      "Trainable params: 1,517,730                                                                                            \n",
      "Non-trainable params: 256                                                                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5477120535714286, 0.5502232142857143, 0.5457589285714286, 0.5452008928571429, 0.5474330357142857, 0.5510602678571429, 0.5493861607142857, 0.5474330357142857, 0.5426897321428571, 0.5452008928571429]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5013786764705882, 0.5445772058823529, 0.5512408088235294, 0.5430836397058824, 0.5477941176470589, 0.5505514705882353, 0.5587086397058824, 0.5591681985294118, 0.5588235294117647, 0.5530790441176471]\n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_6 (Bidirectional) (512, 7, 64)         720896      input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 64)         256         bidirectional_6[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 64)         0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_15 (Dense)                (512, 7, 256)        16384       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_16 (Dense)                (512, 7, 256)        16384       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_18 (Lambda)              (2048, 7, 64)        0           dense_15[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_19 (Lambda)              (2048, 7, 64)        0           dense_16[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_21 (Lambda)              (2048, 7, 7)         0           lambda_18[0][0]                                       \n",
      "                                                                 lambda_19[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "activation_3 (Activation)       (2048, 7, 7)         0           lambda_21[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_17 (Dense)                (512, 7, 256)        16384       y3[0][0]                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________                     \n",
      "dropout_9 (Dropout)             (2048, 7, 7)         0           activation_3[0][0]                                    \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_20 (Lambda)              (2048, 7, 64)        0           dense_17[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_22 (Lambda)              (2048, 7, 64)        0           dropout_9[0][0]                                       \n",
      "                                                                 lambda_20[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_23 (Lambda)              (512, 7, 256)        0           lambda_22[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed_3 (TimeDistrib (512, 7, 32)         8224        lambda_23[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_10 (Dropout)            (512, 7, 32)         0           time_distributed_3[0][0]                              \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization_3 (LayerNor (512, 7, 32)         64          dropout_10[0][0]                                      \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 128)     1424512     input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_7 (Bidirectional) (512, 256)           165888      layer_normalization_3[0][0]                           \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 64)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 256)           1024        bidirectional_7[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 64)      16448       x2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 256)           0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 32)      0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y8 (Dense)                      (512, 64)            16448       y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 32)            0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x9 (Dropout)                    (512, 64)            0           y8[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 32)            1056        x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_19 (Dense)                (512, 8)             520         x9[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 40)            0           x6[0][0]                                              \n",
      "                                                                 dense_19[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_11 (Dropout)            (512, 40)            0           x_y_output_combined[0][0]                             \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             82          dropout_11[0][0]                                      \n",
      "==================================================================================================                     \n",
      "Total params: 2,404,570                                                                                                \n",
      "Trainable params: 2,403,930                                                                                            \n",
      "Non-trainable params: 640                                                                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5558035714285714, 0.5569196428571429, 0.5571986607142857, 0.5552455357142857, 0.5541294642857143, 0.556640625, 0.5571986607142857, 0.5549665178571429, 0.5541294642857143, 0.5502232142857143]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.552734375, 0.5692784926470589, 0.5707720588235294, 0.5760569852941176, 0.572265625, 0.5729549632352942, 0.5731847426470589, 0.5751378676470589, 0.572265625, 0.5691636029411765]\n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_8 (Bidirectional) (512, 7, 256)        2981888     input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 256)        1024        bidirectional_8[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 256)        0           y2[0][0]                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________                     \n",
      "dense_20 (Dense)                (512, 7, 192)        49152       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_21 (Dense)                (512, 7, 192)        49152       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_24 (Lambda)              (1536, 7, 64)        0           dense_20[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_25 (Lambda)              (1536, 7, 64)        0           dense_21[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_27 (Lambda)              (1536, 7, 7)         0           lambda_24[0][0]                                       \n",
      "                                                                 lambda_25[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "activation_4 (Activation)       (1536, 7, 7)         0           lambda_27[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_22 (Dense)                (512, 7, 192)        49152       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_12 (Dropout)            (1536, 7, 7)         0           activation_4[0][0]                                    \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_26 (Lambda)              (1536, 7, 64)        0           dense_22[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_28 (Lambda)              (1536, 7, 64)        0           dropout_12[0][0]                                      \n",
      "                                                                 lambda_26[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_29 (Lambda)              (512, 7, 192)        0           lambda_28[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed_4 (TimeDistrib (512, 7, 16)         3088        lambda_29[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_13 (Dropout)            (512, 7, 16)         0           time_distributed_4[0][0]                              \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization_4 (LayerNor (512, 7, 16)         32          dropout_13[0][0]                                      \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 128)     1424512     input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_9 (Bidirectional) (512, 32)            4352        layer_normalization_4[0][0]                           \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 64)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 32)            128         bidirectional_9[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 16)      4112        x2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 32)            0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 8)       0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y8 (Dense)                      (512, 32)            1056        y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 8)             0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x9 (Dropout)                    (512, 32)            0           y8[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 16)            144         x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_24 (Dense)                (512, 16)            528         x9[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 32)            0           x6[0][0]                                              \n",
      "                                                                 dense_24[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_14 (Dropout)            (512, 32)            0           x_y_output_combined[0][0]                             \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             66          dropout_14[0][0]                                      \n",
      "==================================================================================================                     \n",
      "Total params: 4,568,386                                                                                                \n",
      "Trainable params: 4,567,810                                                                                            \n",
      "Non-trainable params: 576                                                                                              \n",
      "__________________________________________________________________________________________________                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation acc of epoch:                                                                                          \n",
      "[0.501953125, 0.5145089285714286, 0.51953125, 0.5164620535714286, 0.5142299107142857, 0.5301339285714286, 0.5298549107142857, 0.5248325892857143, 0.5418526785714286, 0.5396205357142857]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.48586856617647056, 0.5207950367647058, 0.5166590073529411, 0.5076976102941176, 0.5170036764705882, 0.5155101102941176, 0.5396369485294118, 0.5271139705882353, 0.5452665441176471, 0.5531939338235294]\n",
      "100%|████████████████████████████████████████████████████| 5/5 [01:53<00:00, 23.09s/it, best loss: -0.5613839285714286]\n",
      "Evaluation of best performing model:\n",
      "3584/3584 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 121us/step\n",
      "test_score:  14.733928952898298  test_accuracy:  0.5613839285714286\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dropout': 0.9369741245296254, 'Dropout_1': 1, 'Dropout_2': 0.9649573608743008, 'Dropout_3': 0.31564242696874545, 'Dropout_4': 0.6760874977543352, 'Dropout_5': 0.4789565775993305, 'Dropout_6': 0, 'Dropout_7': 0.20974591564904754, 'd_model': 2, 'd_model_1': 3, 'd_model_2': 0, 'd_model_3': 0, 'filters': 2, 'filters_1': 0, 'units': 1, 'units_1': 1, 'units_2': 1, 'units_3': 0, 'units_4': 3}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    x_train, x_test, y_train, y_test, batch_size, _ ,_, x_train1, x_test1= data()\n",
    "    print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
    "    \n",
    "    best_run, best_model = optim.minimize(model=create_multi_attention_cnn2D_bidirectional_cudnnlstm_multi_input_model, data=data ,algo=tpe.suggest, max_evals=5,trials=Trials(), notebook_name='5.5 Multi_Attention_CNN2D_Bidirectional_CuDNNLSTM_multi_input',rseed=1, verbose=False)\n",
    "    print(\"Evaluation of best performing model:\")\n",
    "    #best_model.save(\"MULTI_ATTENTION_CNN2D_BIDIRECTIONAL_CUDNNLSTM_MULTI_INPUT_bestmodel.h5\")\n",
    "    #print(best_model.get_config())\n",
    "    test_score, test_accuracy = best_model.evaluate([x_test1,x_test], y_test, batch_size=batch_size)\n",
    "    print('test_score: ', test_score, ' test_accuracy: ', test_accuracy)\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "GSPC_7days_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

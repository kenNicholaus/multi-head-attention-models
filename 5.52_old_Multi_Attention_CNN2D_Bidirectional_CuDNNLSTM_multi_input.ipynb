{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIf you are running locally then \\n1. reboot your local machine\\n2. create an environment called 'colab' using anaconda prompt\\nif you have a gpu\\nconda create -n colab python tensorflow-gpu \\nif not \\nconda create -n colab python tensorflow\\n3. to install jupyter notebook\\nconda install jupyter notebook\\n4. to go to the 'colab' environment\\nactivate colab\\n5. change file path to locate this notebook and then type 'jupyter notebook'\\n\\nIf you use colab\\n1. save the data file in your google drive\\n2. goto colab and start running the code\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "If you are running locally then \n",
    "1. reboot your local machine\n",
    "2. create an environment called 'colab' using anaconda prompt\n",
    "if you have a gpu\n",
    "conda create -n colab python tensorflow-gpu \n",
    "if not \n",
    "conda create -n colab python tensorflow\n",
    "3. to install jupyter notebook\n",
    "conda install jupyter notebook\n",
    "4. to go to the 'colab' environment\n",
    "activate colab\n",
    "5. change file path to locate this notebook and then type 'jupyter notebook'\n",
    "\n",
    "If you use colab\n",
    "1. save the data file in your google drive\n",
    "2. goto colab and start running the code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install prominent libraries with specific versions\n",
    "\n",
    "#!pip install tensorflow==1.15.0\n",
    "#!pip install keras==2.2.4-tf\n",
    "#!pip install pandas==0.25.1\n",
    "#!pip install sklearn==0.21.3\n",
    "#!pip install matplotlib==3.2.1\n",
    "#!pip install hyperas\n",
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "sJnnN6xG_yaM",
    "outputId": "b6420ce8-7f05-440c-e2ce-479b5bc1cafc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, CuDNNLSTM, GRU, Input, Activation, Flatten, BatchNormalization, Reshape,Bidirectional\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard, History, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.python.keras import regularizers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from tensorflow.python.keras.optimizers import SGD, RMSprop, Adam, Adadelta\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from sklearn.preprocessing import *\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.layers import Dense, Input, LSTM, Bidirectional, Activation, Conv1D, GRU, TimeDistributed\n",
    "from tensorflow.python.keras.layers import Dropout, Embedding, GlobalMaxPooling1D, MaxPooling1D, Add, Flatten, SpatialDropout1D\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling1D, BatchNormalization, concatenate\n",
    "from tensorflow.python.keras.layers import Reshape, merge, Concatenate, Lambda, Average\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import initializers, regularizers, constraints\n",
    "from tensorflow.python.keras.initializers import *\n",
    "import hyperas\n",
    "import hyperopt\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe, rand\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow.__version__ =  1.10.0\n",
      "sklearn.__version__ =  0.21.3\n",
      "numpy.__version__ =  1.17.0\n",
      "pandas.__version__ =  1.0.1\n",
      "matplotlib.__version__ =  3.1.3\n"
     ]
    }
   ],
   "source": [
    "#Get library versions\n",
    "print(\"tensorflow.__version__ = \", tf.__version__)\n",
    "# import tensorflow.python.keras\n",
    "# print(\"keras.__version__ = \", tensorflow.python.keras.__version__)\n",
    "import sklearn \n",
    "print(\"sklearn.__version__ = \", sklearn.__version__)\n",
    "print(\"numpy.__version__ = \", np.__version__)\n",
    "print(\"pandas.__version__ = \", pd.__version__)\n",
    "import matplotlib\n",
    "print(\"matplotlib.__version__ = \", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed to generate reproduceable results\n",
    "from numpy.random import seed\n",
    "seed(56)\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(56)\n",
    "random.seed(56)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "os.environ['TF_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they do not exist\n",
    "def build_path(dirName):\n",
    "    try:\n",
    "        os.makedirs(dirName)    \n",
    "        print(\"Directory \" , dirName ,  \" Created \")\n",
    "    except:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6043914104907599151\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7139449242\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 934549961190472844\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# to check if GPU is getting used locally.....you need to see CPU as well as GPU in the output\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOs6JYN__51O"
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "  i = 7 # the label target - number of days to predict from the input date\n",
    "  p = 7 #Number of days for target calculated in the data set\n",
    "  batch_size=512\n",
    "  CLASSES = 2\n",
    "  time_steps = 7\n",
    "  ticker='^GSPC'\n",
    "    \n",
    "  # read data\n",
    "  df=pd.read_csv('../^GSPC_7_days_0_return_dtw.csv', index_col = 0, parse_dates = True)\n",
    "    \n",
    "  #add additional rolling mean data  \n",
    "  rm_window =30\n",
    "  rolling_mean = []\n",
    "  for a in range(2,rm_window+1):\n",
    "    df[ticker+'rm_'+str(a)] = df[ticker].rolling(window=rm_window,center=False).mean()\n",
    "    rolling_mean.append(ticker+'rm_'+str(a))\n",
    "    \n",
    "  # create label\n",
    "  targets=pd.DataFrame([])\n",
    "  for j in range (1, p+1):\n",
    "    targets=targets.append(df[ticker+'_{}d_target'.format(j)])\n",
    "    targets=targets.append(df[ticker+'_{}d'.format(j)])\n",
    "  targets=targets.T\n",
    "  df=df.drop(targets.columns, axis=1)\n",
    "  df=df[rm_window:-i]\n",
    "  targets=targets[rm_window:-i]\n",
    "  y=targets['^GSPC_{}d_target'.format(i)]\n",
    "\n",
    "  #check for NaN and remove\n",
    "  df.isna().mean().sum()\n",
    "  y.isna().mean().sum()\n",
    "  remove_list=[]\n",
    "  for i in df.isnull().any().iteritems():\n",
    "    if i[1] == True:\n",
    "      remove_list.append(i[0])\n",
    "  df=df.drop(remove_list, axis=1)\n",
    "  df.isnull().any().mean()\n",
    " \n",
    "  # add percent change\n",
    "  df=df.pct_change()\n",
    "  df=df.replace([np.inf, -np.inf],np.nan) \n",
    "  df.fillna(0, inplace=True)\n",
    "  df.isnull().any().mean()\n",
    "    \n",
    "  # apply preprocessing \n",
    "  x_scaler=RobustScaler()\n",
    "  x = x_scaler.fit_transform(df)\n",
    "  # x_pred = x_scaler.fit_transform(x_pred)\n",
    "  del df\n",
    "  y=y.values\n",
    "    \n",
    "  # apply time steps\n",
    "  def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "      v = X[i:(i + time_steps)]\n",
    "      Xs.append(v)\n",
    "      ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "  x, y = create_dataset(x, y, time_steps)\n",
    "\n",
    "  # create train and test dataset\n",
    "  x_train, x_test, y_train, y_test=train_test_split(x,y, train_size=0.7, random_state=54)\n",
    "  x_train = x_train.astype('float32')\n",
    "  x_test = x_test.astype('float32')\n",
    "  #y_train = y_train.astype('float32')\n",
    "  #y_test = y_test.astype('float32')\n",
    "  y_train = np_utils.to_categorical(y_train, CLASSES, \n",
    "                                    #dtype='float32'\n",
    "                                   )\n",
    "  y_test = np_utils.to_categorical(y_test, CLASSES, \n",
    "                                   #dtype='float32'\n",
    "                                  )\n",
    "    \n",
    "  # adjustment for batch_size\n",
    "  train_start = x_train.shape[0]%batch_size\n",
    "  test_start = x_test.shape[0]%batch_size\n",
    "  x_train = x_train[train_start:]\n",
    "  y_train = y_train[train_start:]\n",
    "  x_test = x_test[test_start:]\n",
    "  y_test = y_test[test_start:]\n",
    "\n",
    "  #reshape for 2D\n",
    "  x_train1 = x_train.reshape(x_train.shape[0], 1, x_train.shape[1], x_train.shape[2]) \n",
    "  x_test1 = x_test.reshape(x_test.shape[0], 1, x_test.shape[1], x_test.shape[2])  \n",
    "\n",
    "  embed_size = 60\n",
    "\n",
    "  return x_train, x_test, y_train, y_test, batch_size, time_steps, embed_size, x_train1, x_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rc8hDOIbADgQ"
   },
   "outputs": [],
   "source": [
    "def create_multi_attention_cnn2D_bidirectional_cudnnlstm_multi_input_model_2(x_train, x_test, y_train, y_test, batch_size, time_steps, embed_size, x_train1, x_test1):\n",
    "    \n",
    "    class LayerNormalization(Layer):\n",
    "        def __init__(self, eps=1e-6, **kwargs):\n",
    "            self.eps = eps\n",
    "            super(LayerNormalization, self).__init__(**kwargs)\n",
    "        def build(self, input_shape):\n",
    "            self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],initializer=Ones(), trainable=True)\n",
    "            self.beta = self.add_weight(name='beta', shape=input_shape[-1:],initializer=Zeros(), trainable=True)\n",
    "            super(LayerNormalization, self).build(input_shape)\n",
    "        def call(self, x):\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            std = K.std(x, axis=-1, keepdims=True)\n",
    "            return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return input_shape\n",
    "\n",
    "    class ScaledDotProductAttention():\n",
    "        def __init__(self, d_model, attn_dropout=0.1):\n",
    "            self.temper = np.sqrt(d_model)\n",
    "            self.dropout = Dropout(attn_dropout)\n",
    "        def __call__(self, q, k, v, mask):\n",
    "            attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k])\n",
    "            if mask is not None:\n",
    "                mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
    "                attn = Add()([attn, mmask])\n",
    "            attn = Activation('softmax')(attn)\n",
    "            attn = self.dropout(attn)\n",
    "            output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
    "            return output, attn\n",
    "\n",
    "    class MultiHeadAttention():\n",
    "        # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
    "        def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True):\n",
    "            self.mode = mode\n",
    "            self.n_head = n_head\n",
    "            self.d_k = d_k\n",
    "            self.d_v = d_v\n",
    "            self.dropout = dropout\n",
    "            if mode == 0:\n",
    "                self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
    "                self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
    "                self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
    "            elif mode == 1:\n",
    "                self.qs_layers = []\n",
    "                self.ks_layers = []\n",
    "                self.vs_layers = []\n",
    "                for _ in range(n_head):\n",
    "                    self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                    self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
    "                    self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
    "            self.attention = ScaledDotProductAttention(d_model)\n",
    "            self.layer_norm = LayerNormalization() if use_norm else None\n",
    "            self.w_o = TimeDistributed(Dense(d_model))\n",
    "\n",
    "        def __call__(self, q, k, v, mask=None):\n",
    "            d_k, d_v = self.d_k, self.d_v\n",
    "            n_head = self.n_head\n",
    "\n",
    "            if self.mode == 0:\n",
    "                qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
    "                ks = self.ks_layer(k)\n",
    "                vs = self.vs_layer(v)\n",
    "\n",
    "                def reshape1(x):\n",
    "                    s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
    "                    x = tf.reshape(x, [s[0], s[1], n_head, d_k])\n",
    "                    x = tf.transpose(x, [2, 0, 1, 3])  \n",
    "                    x = tf.reshape(x, [-1, s[1], d_k])  # [n_head * batch_size, len_q, d_k]\n",
    "                    return x\n",
    "                qs = Lambda(reshape1)(qs)\n",
    "                ks = Lambda(reshape1)(ks)\n",
    "                vs = Lambda(reshape1)(vs)\n",
    "\n",
    "                if mask is not None:\n",
    "                    mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
    "                head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
    "\n",
    "                def reshape2(x):\n",
    "                    s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
    "                    x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
    "                    x = tf.transpose(x, [1, 2, 0, 3])\n",
    "                    x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
    "                    return x\n",
    "                head = Lambda(reshape2)(head)\n",
    "            elif self.mode == 1:\n",
    "                heads = []; attns = []\n",
    "                for i in range(n_head):\n",
    "                    qs = self.qs_layers[i](q)   \n",
    "                    ks = self.ks_layers[i](k) \n",
    "                    vs = self.vs_layers[i](v) \n",
    "                    head, attn = self.attention(qs, ks, vs, mask)\n",
    "                    heads.append(head); attns.append(attn)\n",
    "                head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
    "                attn = Concatenate()(attns) if n_head > 1 else attns[0]\n",
    "\n",
    "            outputs = self.w_o(head)\n",
    "            outputs = Dropout(self.dropout)(outputs)\n",
    "            if not self.layer_norm: return outputs, attn\n",
    "            # outputs = Add()([outputs, q]) # sl: fix\n",
    "            return self.layer_norm(outputs), attn\n",
    "\n",
    "    class PositionwiseFeedForward():\n",
    "        def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
    "            self.w_1 = Conv1D(d_inner_hid, 1, activation='relu')\n",
    "            self.w_2 = Conv1D(d_hid, 1)\n",
    "            self.layer_norm = LayerNormalization()\n",
    "            self.dropout = Dropout(dropout)\n",
    "        def __call__(self, x):\n",
    "            output = self.w_1(x) \n",
    "            output = self.w_2(output)\n",
    "            output = self.dropout(output)\n",
    "            output = Add()([output, x])\n",
    "            return self.layer_norm(output)\n",
    "\n",
    "    class EncoderLayer():\n",
    "        def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
    "            self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "            self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
    "        def __call__(self, enc_input, mask=None):\n",
    "            output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
    "            output = self.pos_ffn_layer(output)\n",
    "            return output, slf_attn\n",
    "\n",
    "\n",
    "    def GetPosEncodingMatrix(max_len, d_emb):\n",
    "        pos_enc = np.array([\n",
    "            [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
    "            if pos != 0 else np.zeros(d_emb) \n",
    "                for pos in range(max_len)\n",
    "                ])\n",
    "        pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "        pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "        return pos_enc\n",
    "\n",
    "    def GetPadMask(q, k):\n",
    "        ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
    "        mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
    "        mask = K.batch_dot(ones, mask, axes=[2,1])\n",
    "        return mask\n",
    "\n",
    "    def GetSubMask(s):\n",
    "        len_s = tf.shape(s)[1]\n",
    "        bs = tf.shape(s)[:1]\n",
    "        mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
    "        return mask\n",
    "\n",
    "    class Transformer():\n",
    "        def __init__(self, len_limit, embedding_matrix, d_model=embed_size, \\\n",
    "                  d_inner_hid=512, n_head=10, d_k=64, d_v=64, layers=2, dropout=0.1, \\\n",
    "                  share_word_emb=False, **kwargs):\n",
    "            self.name = 'Transformer'\n",
    "            self.len_limit = len_limit\n",
    "            self.src_loc_info = False # True # sl: fix later\n",
    "            self.d_model = d_model\n",
    "            self.decode_model = None\n",
    "            d_emb = d_model\n",
    "\n",
    "            pos_emb = Embedding(len_limit, d_emb, trainable=False, \\\n",
    "                                weights=[GetPosEncodingMatrix(len_limit, d_emb)])\n",
    "\n",
    "            i_word_emb = Embedding(max_features, d_emb, weights=[embedding_matrix]) # Add Kaggle provided embedding here\n",
    "\n",
    "            self.encoder = Encoder(d_model, d_inner_hid, n_head, d_k, d_v, layers, dropout, \\\n",
    "                                   word_emb=i_word_emb, pos_emb=pos_emb)\n",
    "\n",
    "\n",
    "        def get_pos_seq(self, x):\n",
    "            mask = K.cast(K.not_equal(x, 0), 'int32')\n",
    "            pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
    "            return pos * mask\n",
    "\n",
    "        \n",
    "    # define two sets of inputs(it can be the same or different)\n",
    "    inputA = Input(batch_shape=(batch_size, x_train1.shape[1], x_train1.shape[2], x_train1.shape[3]), name='input_1')\n",
    "    inputB = Input(batch_shape=(batch_size, x_train.shape[1], x_train.shape[2]), name='input_2')\n",
    "\n",
    "    # the first branch operates on the first input\n",
    "    x1 = Conv2D(filters = {{choice([32, 64, 128])}},name='x1', kernel_size =2,padding='same', activation='relu')(inputA)\n",
    "    x2 = MaxPooling2D(pool_size=(2,2), strides=(2,2), data_format=\"channels_first\", name='x2')(x1)\n",
    "    x3 = Conv2D(filters ={{choice([16, 32, 64])}}, name='x3', kernel_size =2,padding='same', activation='relu')(x2)\n",
    "    x4 = MaxPooling2D(pool_size=(2,2), strides=(2,2), data_format=\"channels_first\", name='x4')(x3)\n",
    "    x5 = Flatten(name='x5')(x4)\n",
    "    x6 = Dense(units = {{choice([4, 8,16,32])}},name='x6', activation='relu')(x5)\n",
    "    x = Model(inputA, x6, name='x')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y1 = Bidirectional(CuDNNLSTM(units = {{choice([16,32, 64, 128])}}, name='x1',  kernel_regularizer=regularizers.l2(0.03), \n",
    "              bias_regularizer=regularizers.l1(0.03),\n",
    "              return_sequences=True, stateful = True))(inputB)\n",
    "    y2 = BatchNormalization(name='y2')(y1)\n",
    "    y3 = Dropout({{uniform(0, 1)}},name='y3')(y2)\n",
    "    \n",
    "    y4, slf_attn = MultiHeadAttention(n_head={{choice([3, 4, 5,6,7,8,9,10,11,12])}},\n",
    "                                      d_model={{choice([32, 64, 128])}}, d_k=64, d_v=64, dropout={{uniform(0, 1)}})(y3, y3, y3)\n",
    "    print(y4.shape)\n",
    "    print(slf_attn.shape)\n",
    "    y5 = Bidirectional(CuDNNLSTM(units = {{choice([4, 8,16,32])}},name='y5',  kernel_regularizer=regularizers.l2(0.03), \n",
    "              bias_regularizer=regularizers.l1(0.03),\n",
    "              return_sequences=False,stateful = True))(y4)\n",
    "    y6 = BatchNormalization(name='y6')(y5)\n",
    "    y7 = Dropout({{uniform(0, 1)}},name='y7')(y6)\n",
    "        \n",
    "    y = Model(inputB, y7, name='y')\n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = Concatenate(name='x_y_output_combined')([x.output, y.output])\n",
    "\n",
    "\n",
    "    # combined outputs\n",
    "    z = Dense(2, name='z', activation=\"softmax\")(combined)\n",
    "\n",
    "    # our model will accept the inputs of the two branches and then output buy or sell\n",
    "    model = Model(inputs=[inputA, inputB], outputs=z)\n",
    "    \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer = Adam(lr=0.001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    result = model.fit([x_train1, x_train],y_train,batch_size=batch_size,epochs=10,validation_data=([x_test1, x_test], y_test), verbose=0)\n",
    "    \n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "\n",
    "    print('Best validation acc of epoch:', result.history['val_acc'])\n",
    "    print('Train acc of epoch:', result.history['acc'])\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HcxtusN4AK8y",
    "outputId": "43d151c2-cf3b-4ab8-e95f-7c48cef1da49",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8704, 7, 2782) (8704, 2) (3584, 7, 2782) (3584, 2)\n",
      "(512, 7, 128)                                                                                                          \n",
      "(5120, 7, 7)                                                                                                           \n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional (Bidirectional)   (512, 7, 32)         358400      input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 32)         128         bidirectional[0][0]                                   \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 32)         0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense (Dense)                   (512, 7, 640)        20480       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_1 (Dense)                 (512, 7, 640)        20480       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda (Lambda)                 (5120, 7, 64)        0           dense[0][0]                                           \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_1 (Lambda)               (5120, 7, 64)        0           dense_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_3 (Lambda)               (5120, 7, 7)         0           lambda[0][0]                                          \n",
      "                                                                 lambda_1[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "activation (Activation)         (5120, 7, 7)         0           lambda_3[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_2 (Dense)                 (512, 7, 640)        20480       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout (Dropout)               (5120, 7, 7)         0           activation[0][0]                                      \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_2 (Lambda)               (5120, 7, 64)        0           dense_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_4 (Lambda)               (5120, 7, 64)        0           dropout[0][0]                                         \n",
      "                                                                 lambda_2[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_5 (Lambda)               (512, 7, 640)        0           lambda_4[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 128)     1424512     input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed (TimeDistribut (512, 7, 128)        82048       lambda_5[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 64)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_1 (Dropout)             (512, 7, 128)        0           time_distributed[0][0]                                \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 32)      8224        x2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization (LayerNorma (512, 7, 128)        256         dropout_1[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 16)      0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_1 (Bidirectional) (512, 8)             4288        layer_normalization[0][0]                             \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 16)            0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 8)             32          bidirectional_1[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 4)             68          x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 8)             0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 12)            0           x6[0][0]                                              \n",
      "                                                                 y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             26          x_y_output_combined[0][0]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================                     \n",
      "Total params: 1,939,422                                                                                                \n",
      "Trainable params: 1,939,342                                                                                            \n",
      "Non-trainable params: 80                                                                                               \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5426897321428571, 0.54296875, 0.5491071428571429, 0.5276227678571429, 0.5340401785714286, 0.5354352678571429, 0.5401785714285714, 0.5516183035714286, 0.5574776785714286, 0.5558035714285714]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.568359375, 0.5420496323529411, 0.5480238970588235, 0.5372242647058824, 0.5291819852941176, 0.5389476102941176, 0.5248161764705882, 0.5305606617647058, 0.5388327205882353, 0.5301011029411765]\n",
      "(512, 7, 64)                                                                                                           \n",
      "(2048, 7, 7)                                                                                                           \n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_2 (Bidirectional) (512, 7, 32)         358400      input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 32)         128         bidirectional_2[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 32)         0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_4 (Dense)                 (512, 7, 256)        8192        y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_5 (Dense)                 (512, 7, 256)        8192        y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_6 (Lambda)               (2048, 7, 64)        0           dense_4[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_7 (Lambda)               (2048, 7, 64)        0           dense_5[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_9 (Lambda)               (2048, 7, 7)         0           lambda_6[0][0]                                        \n",
      "                                                                 lambda_7[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "activation_1 (Activation)       (2048, 7, 7)         0           lambda_9[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_6 (Dense)                 (512, 7, 256)        8192        y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_2 (Dropout)             (2048, 7, 7)         0           activation_1[0][0]                                    \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_8 (Lambda)               (2048, 7, 64)        0           dense_6[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_10 (Lambda)              (2048, 7, 64)        0           dropout_2[0][0]                                       \n",
      "                                                                 lambda_8[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_11 (Lambda)              (512, 7, 256)        0           lambda_10[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 128)     1424512     input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed_1 (TimeDistrib (512, 7, 64)         16448       lambda_11[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 64)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_3 (Dropout)             (512, 7, 64)         0           time_distributed_1[0][0]                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 16)      4112        x2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization_1 (LayerNor (512, 7, 64)         128         dropout_3[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 8)       0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_3 (Bidirectional) (512, 64)            25088       layer_normalization_1[0][0]                           \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 8)             0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 64)            256         bidirectional_3[0][0]                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 8)             72          x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 64)            0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 72)            0           x6[0][0]                                              \n",
      "                                                                 y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             146         x_y_output_combined[0][0]                             \n",
      "==================================================================================================                     \n",
      "Total params: 1,853,866                                                                                                \n",
      "Trainable params: 1,853,674                                                                                            \n",
      "Non-trainable params: 192                                                                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5382254464285714, 0.5318080357142857, 0.5432477678571429, 0.5379464285714286, 0.5323660714285714, 0.5304129464285714, 0.5281808035714286, 0.5357142857142857, 0.5412946428571429, 0.541015625]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5230928308823529, 0.5349264705882353, 0.5381433823529411, 0.5428538602941176, 0.5359604779411765, 0.5356158088235294, 0.5317095588235294, 0.5305606617647058, 0.5515854779411765, 0.5528492647058824]\n",
      "(512, 7, 128)                                                                                                          \n",
      "(6144, 7, 7)                                                                                                           \n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_4 (Bidirectional) (512, 7, 64)         720896      input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 64)         256         bidirectional_4[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 64)         0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_8 (Dense)                 (512, 7, 768)        49152       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_9 (Dense)                 (512, 7, 768)        49152       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_12 (Lambda)              (6144, 7, 64)        0           dense_8[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_13 (Lambda)              (6144, 7, 64)        0           dense_9[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_15 (Lambda)              (6144, 7, 7)         0           lambda_12[0][0]                                       \n",
      "                                                                 lambda_13[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "activation_2 (Activation)       (6144, 7, 7)         0           lambda_15[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_10 (Dense)                (512, 7, 768)        49152       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_4 (Dropout)             (6144, 7, 7)         0           activation_2[0][0]                                    \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_14 (Lambda)              (6144, 7, 64)        0           dense_10[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_16 (Lambda)              (6144, 7, 64)        0           dropout_4[0][0]                                       \n",
      "                                                                 lambda_14[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_17 (Lambda)              (512, 7, 768)        0           lambda_16[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 64)      712256      input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed_2 (TimeDistrib (512, 7, 128)        98432       lambda_17[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 32)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_5 (Dropout)             (512, 7, 128)        0           time_distributed_2[0][0]                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 64)      8256        x2[0][0]                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization_2 (LayerNor (512, 7, 128)        256         dropout_5[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 32)      0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_5 (Bidirectional) (512, 32)            18688       layer_normalization_2[0][0]                           \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 32)            0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 32)            128         bidirectional_5[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 32)            1056        x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 32)            0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 64)            0           x6[0][0]                                              \n",
      "                                                                 y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             130         x_y_output_combined[0][0]                             \n",
      "==================================================================================================                     \n",
      "Total params: 1,707,810                                                                                                \n",
      "Trainable params: 1,707,618                                                                                            \n",
      "Non-trainable params: 192                                                                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5560825892857143, 0.5569196428571429, 0.5571986607142857, 0.5546875, 0.5571986607142857, 0.5569196428571429, 0.546875, 0.5365513392857143, 0.5387834821428571, 0.525390625]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5736443014705882, 0.5758272058823529, 0.5769761029411765, 0.5772058823529411, 0.5766314338235294, 0.5777803308823529, 0.5731847426470589, 0.5606617647058824, 0.5642233455882353, 0.5621553308823529]\n",
      "(512, 7, 128)                                                                                                          \n",
      "(2048, 7, 7)                                                                                                           \n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_6 (Bidirectional) (512, 7, 64)         720896      input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 64)         256         bidirectional_6[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 64)         0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_12 (Dense)                (512, 7, 256)        16384       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_13 (Dense)                (512, 7, 256)        16384       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_18 (Lambda)              (2048, 7, 64)        0           dense_12[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_19 (Lambda)              (2048, 7, 64)        0           dense_13[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_21 (Lambda)              (2048, 7, 7)         0           lambda_18[0][0]                                       \n",
      "                                                                 lambda_19[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "activation_3 (Activation)       (2048, 7, 7)         0           lambda_21[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_14 (Dense)                (512, 7, 256)        16384       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_6 (Dropout)             (2048, 7, 7)         0           activation_3[0][0]                                    \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_20 (Lambda)              (2048, 7, 64)        0           dense_14[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_22 (Lambda)              (2048, 7, 64)        0           dropout_6[0][0]                                       \n",
      "                                                                 lambda_20[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_23 (Lambda)              (512, 7, 256)        0           lambda_22[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 (Conv2D)                     (512, 1, 7, 64)      712256      input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed_3 (TimeDistrib (512, 7, 128)        32896       lambda_23[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 32)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_7 (Dropout)             (512, 7, 128)        0           time_distributed_3[0][0]                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 64)      8256        x2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization_3 (LayerNor (512, 7, 128)        256         dropout_7[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 32)      0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_7 (Bidirectional) (512, 32)            18688       layer_normalization_3[0][0]                           \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 32)            0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 32)            128         bidirectional_7[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 32)            1056        x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 32)            0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 64)            0           x6[0][0]                                              \n",
      "                                                                 y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             130         x_y_output_combined[0][0]                             \n",
      "==================================================================================================                     \n",
      "Total params: 1,543,970                                                                                                \n",
      "Trainable params: 1,543,778                                                                                            \n",
      "Non-trainable params: 192                                                                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.45870535714285715, 0.48046875, 0.48995535714285715, 0.4790736607142857, 0.49720982142857145, 0.49441964285714285, 0.5044642857142857, 0.5147879464285714, 0.5309709821428571, 0.5172991071428571]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.4397977941176471, 0.4563419117647059, 0.4895450367647059, 0.48058363970588236, 0.49942555147058826, 0.5130974264705882, 0.5071231617647058, 0.5217141544117647, 0.5364200367647058, 0.5349264705882353]\n",
      "(512, 7, 128)                                                                                                          \n",
      "(5632, 7, 7)                                                                                                           \n",
      "__________________________________________________________________________________________________                     \n",
      "Layer (type)                    Output Shape         Param #     Connected to                                          \n",
      "==================================================================================================                     \n",
      "input_2 (InputLayer)            (512, 7, 2782)       0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_8 (Bidirectional) (512, 7, 128)        1458176     input_2[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "y2 (BatchNormalization)         (512, 7, 128)        512         bidirectional_8[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "y3 (Dropout)                    (512, 7, 128)        0           y2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_16 (Dense)                (512, 7, 704)        90112       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_17 (Dense)                (512, 7, 704)        90112       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_24 (Lambda)              (5632, 7, 64)        0           dense_16[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_25 (Lambda)              (5632, 7, 64)        0           dense_17[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_27 (Lambda)              (5632, 7, 7)         0           lambda_24[0][0]                                       \n",
      "                                                                 lambda_25[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "activation_4 (Activation)       (5632, 7, 7)         0           lambda_27[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "dense_18 (Dense)                (512, 7, 704)        90112       y3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_8 (Dropout)             (5632, 7, 7)         0           activation_4[0][0]                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________                     \n",
      "lambda_26 (Lambda)              (5632, 7, 64)        0           dense_18[0][0]                                        \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_28 (Lambda)              (5632, 7, 64)        0           dropout_8[0][0]                                       \n",
      "                                                                 lambda_26[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "input_1 (InputLayer)            (512, 1, 7, 2782)    0                                                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "lambda_29 (Lambda)              (512, 7, 704)        0           lambda_28[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x1 (Conv2D)                     (512, 1, 7, 32)      356128      input_1[0][0]                                         \n",
      "__________________________________________________________________________________________________                     \n",
      "time_distributed_4 (TimeDistrib (512, 7, 128)        90240       lambda_29[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x2 (MaxPooling2D)               (512, 1, 3, 16)      0           x1[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "dropout_9 (Dropout)             (512, 7, 128)        0           time_distributed_4[0][0]                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x3 (Conv2D)                     (512, 1, 3, 16)      1040        x2[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "layer_normalization_4 (LayerNor (512, 7, 128)        256         dropout_9[0][0]                                       \n",
      "__________________________________________________________________________________________________                     \n",
      "x4 (MaxPooling2D)               (512, 1, 1, 8)       0           x3[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "bidirectional_9 (Bidirectional) (512, 32)            18688       layer_normalization_4[0][0]                           \n",
      "__________________________________________________________________________________________________                     \n",
      "x5 (Flatten)                    (512, 8)             0           x4[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y6 (BatchNormalization)         (512, 32)            128         bidirectional_9[0][0]                                 \n",
      "__________________________________________________________________________________________________                     \n",
      "x6 (Dense)                      (512, 16)            144         x5[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "y7 (Dropout)                    (512, 32)            0           y6[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "x_y_output_combined (Concatenat (512, 48)            0           x6[0][0]                                              \n",
      "                                                                 y7[0][0]                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "z (Dense)                       (512, 2)             98          x_y_output_combined[0][0]                             \n",
      "==================================================================================================                     \n",
      "Total params: 2,195,746                                                                                                \n",
      "Trainable params: 2,195,426                                                                                            \n",
      "Non-trainable params: 320                                                                                              \n",
      "__________________________________________________________________________________________________                     \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.4447544642857143, 0.4447544642857143, 0.4447544642857143, 0.4447544642857143, 0.4447544642857143, 0.4447544642857143, 0.4447544642857143, 0.4447544642857143, 0.4447544642857143, 0.4447544642857143]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.4312959558823529, 0.42566636029411764, 0.42566636029411764, 0.42566636029411764, 0.42566636029411764, 0.42566636029411764, 0.42566636029411764, 0.42566636029411764, 0.42566636029411764, 0.42566636029411764]\n",
      "100%|| 5/5 [01:55<00:00, 23.36s/it, best loss: -0.5574776785714286]\n",
      "Evaluation of best performing model:\n",
      "3584/3584 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 112us/step\n",
      "test_score:  2.8923708370753696  test_accuracy:  0.5558035714285714\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dropout': 0.7862635378304327, 'Dropout_1': 0.09057019926571874, 'Dropout_2': 0.5782233008102186, 'filters': 2, 'filters_1': 1, 'filters_2': 2, 'n_head': 7, 'units': 0, 'units_1': 0, 'units_2': 0}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    x_train, x_test, y_train, y_test, batch_size, _ ,_, x_train1, x_test1= data()\n",
    "    print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
    "    \n",
    "    best_run, best_model = optim.minimize(model=create_multi_attention_cnn2D_bidirectional_cudnnlstm_multi_input_model_2, data=data ,algo=tpe.suggest, max_evals=5,trials=Trials(), notebook_name='5.52 Multi_Attention_CNN2D_Bidirectional_CuDNNLSTM_multi_input',rseed=1, verbose=False)\n",
    "    print(\"Evaluation of best performing model:\")\n",
    "    #best_model.save(\"MULTI_ATTENTION_CNN2D_BIDIRECTIONAL_CUDNNLSTM_MULTI_INPUT_2_bestmodel.h5\")\n",
    "    #print(best_model.get_config())\n",
    "    test_score, test_accuracy = best_model.evaluate([x_test1,x_test], y_test, batch_size=batch_size)\n",
    "    print('test_score: ', test_score, ' test_accuracy: ', test_accuracy)\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "GSPC_7days_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
